-- This file and its contents are licensed under the Timescale License.
-- Please see the included NOTICE for copyright information and
-- LICENSE-TIMESCALE for a copy of the license.
\set EXPLAIN_ANALYZE 'EXPLAIN (analyze,costs off,timing off,summary off)'
CREATE TABLE continuous_agg_test(time int, data int);
select create_hypertable('continuous_agg_test', 'time', chunk_time_interval=> 10);
NOTICE:  adding not-null constraint to column "time"
        create_hypertable         
----------------------------------
 (1,public,continuous_agg_test,t)
(1 row)

CREATE OR REPLACE FUNCTION integer_now_test1() returns int LANGUAGE SQL STABLE as $$ SELECT coalesce(max(time), 0) FROM continuous_agg_test $$;
SELECT set_integer_now_func('continuous_agg_test', 'integer_now_test1');
 set_integer_now_func 
----------------------
 
(1 row)

-- watermark tabels start out empty
SELECT * FROM _timescaledb_catalog.continuous_aggs_invalidation_threshold;
 hypertable_id | watermark 
---------------+-----------
(0 rows)

SELECT * from _timescaledb_catalog.continuous_aggs_hypertable_invalidation_log;
 hypertable_id | lowest_modified_value | greatest_modified_value 
---------------+-----------------------+-------------------------
(0 rows)

-- inserting into a table that does not have continuous_agg_insert_trigger doesn't change the watermark
INSERT INTO continuous_agg_test VALUES (10, 1), (11, 2), (21, 3), (22, 4);
SELECT * FROM _timescaledb_catalog.continuous_aggs_invalidation_threshold;
 hypertable_id | watermark 
---------------+-----------
(0 rows)

SELECT * from _timescaledb_catalog.continuous_aggs_hypertable_invalidation_log;
 hypertable_id | lowest_modified_value | greatest_modified_value 
---------------+-----------------------+-------------------------
(0 rows)

\c :TEST_DBNAME :ROLE_SUPERUSER
CREATE TABLE continuous_agg_test_mat(time int);
select create_hypertable('continuous_agg_test_mat', 'time', chunk_time_interval=> 10);
NOTICE:  adding not-null constraint to column "time"
          create_hypertable           
--------------------------------------
 (2,public,continuous_agg_test_mat,t)
(1 row)

INSERT INTO _timescaledb_catalog.continuous_agg VALUES (2, 1, NULL, '','','','',0,'','');
\c :TEST_DBNAME :ROLE_DEFAULT_PERM_USER
-- create the trigger
CREATE TRIGGER continuous_agg_insert_trigger
    AFTER INSERT ON continuous_agg_test
    FOR EACH ROW EXECUTE FUNCTION _timescaledb_functions.continuous_agg_invalidation_trigger(1);
-- inserting into the table still doesn't change the watermark since there's no
-- continuous_aggs_invalidation_threshold. We treat that case as a invalidation_watermark of
-- BIG_INT_MIN, since the first run of the aggregation will need to scan the
-- entire table anyway.
INSERT INTO continuous_agg_test VALUES (10, 1), (11, 2), (21, 3), (22, 4);
SELECT * FROM _timescaledb_catalog.continuous_aggs_invalidation_threshold;
 hypertable_id | watermark 
---------------+-----------
(0 rows)

SELECT * from _timescaledb_catalog.continuous_aggs_hypertable_invalidation_log;
 hypertable_id | lowest_modified_value | greatest_modified_value 
---------------+-----------------------+-------------------------
(0 rows)

-- set the continuous_aggs_invalidation_threshold to 15, any insertions below that value need an invalidation
\c :TEST_DBNAME :ROLE_SUPERUSER
INSERT INTO _timescaledb_catalog.continuous_aggs_invalidation_threshold VALUES (1, 15);
\c :TEST_DBNAME :ROLE_DEFAULT_PERM_USER
INSERT INTO continuous_agg_test VALUES (10, 1), (11, 2), (21, 3), (22, 4);
SELECT * FROM _timescaledb_catalog.continuous_aggs_invalidation_threshold;
 hypertable_id | watermark 
---------------+-----------
             1 |        15
(1 row)

SELECT * from _timescaledb_catalog.continuous_aggs_hypertable_invalidation_log;
 hypertable_id | lowest_modified_value | greatest_modified_value 
---------------+-----------------------+-------------------------
             1 |                    10 |                      22
(1 row)

-- INSERTs only above the continuous_aggs_invalidation_threshold won't change the continuous_aggs_hypertable_invalidation_log
INSERT INTO continuous_agg_test VALUES (21, 3), (22, 4);
SELECT * FROM _timescaledb_catalog.continuous_aggs_invalidation_threshold;
 hypertable_id | watermark 
---------------+-----------
             1 |        15
(1 row)

SELECT * from _timescaledb_catalog.continuous_aggs_hypertable_invalidation_log;
 hypertable_id | lowest_modified_value | greatest_modified_value 
---------------+-----------------------+-------------------------
             1 |                    10 |                      22
(1 row)

-- INSERTs only below the continuous_aggs_invalidation_threshold will change the continuous_aggs_hypertable_invalidation_log
INSERT INTO continuous_agg_test VALUES (10, 1), (11, 2);
SELECT * FROM _timescaledb_catalog.continuous_aggs_invalidation_threshold;
 hypertable_id | watermark 
---------------+-----------
             1 |        15
(1 row)

SELECT * from _timescaledb_catalog.continuous_aggs_hypertable_invalidation_log;
 hypertable_id | lowest_modified_value | greatest_modified_value 
---------------+-----------------------+-------------------------
             1 |                    10 |                      22
             1 |                    10 |                      11
(2 rows)

-- test INSERTing other values
INSERT INTO continuous_agg_test VALUES (1, 7), (12, 6), (24, 5), (51, 4);
SELECT * FROM _timescaledb_catalog.continuous_aggs_invalidation_threshold;
 hypertable_id | watermark 
---------------+-----------
             1 |        15
(1 row)

SELECT * from _timescaledb_catalog.continuous_aggs_hypertable_invalidation_log;
 hypertable_id | lowest_modified_value | greatest_modified_value 
---------------+-----------------------+-------------------------
             1 |                    10 |                      22
             1 |                    10 |                      11
             1 |                     1 |                      51
(3 rows)

-- INSERT after dropping a COLUMN
ALTER TABLE continuous_agg_test DROP COLUMN data;
INSERT INTO continuous_agg_test VALUES (-1), (-2), (-3), (-4);
SELECT * FROM _timescaledb_catalog.continuous_aggs_invalidation_threshold;
 hypertable_id | watermark 
---------------+-----------
             1 |        15
(1 row)

SELECT * from _timescaledb_catalog.continuous_aggs_hypertable_invalidation_log;
 hypertable_id | lowest_modified_value | greatest_modified_value 
---------------+-----------------------+-------------------------
             1 |                    10 |                      22
             1 |                    10 |                      11
             1 |                     1 |                      51
             1 |                    -4 |                      -1
(4 rows)

INSERT INTO continuous_agg_test VALUES (100);
SELECT * FROM _timescaledb_catalog.continuous_aggs_invalidation_threshold;
 hypertable_id | watermark 
---------------+-----------
             1 |        15
(1 row)

SELECT * from _timescaledb_catalog.continuous_aggs_hypertable_invalidation_log;
 hypertable_id | lowest_modified_value | greatest_modified_value 
---------------+-----------------------+-------------------------
             1 |                    10 |                      22
             1 |                    10 |                      11
             1 |                     1 |                      51
             1 |                    -4 |                      -1
(4 rows)

-- INSERT after adding a COLUMN
ALTER TABLE continuous_agg_test ADD COLUMN d BOOLEAN;
INSERT INTO continuous_agg_test VALUES (-6, true), (-7, false), (-3, true), (-4, false);
SELECT * FROM _timescaledb_catalog.continuous_aggs_invalidation_threshold;
 hypertable_id | watermark 
---------------+-----------
             1 |        15
(1 row)

SELECT * from _timescaledb_catalog.continuous_aggs_hypertable_invalidation_log;
 hypertable_id | lowest_modified_value | greatest_modified_value 
---------------+-----------------------+-------------------------
             1 |                    10 |                      22
             1 |                    10 |                      11
             1 |                     1 |                      51
             1 |                    -4 |                      -1
             1 |                    -7 |                      -3
(5 rows)

INSERT INTO continuous_agg_test VALUES (120, false), (200, true);
SELECT * FROM _timescaledb_catalog.continuous_aggs_invalidation_threshold;
 hypertable_id | watermark 
---------------+-----------
             1 |        15
(1 row)

SELECT * from _timescaledb_catalog.continuous_aggs_hypertable_invalidation_log;
 hypertable_id | lowest_modified_value | greatest_modified_value 
---------------+-----------------------+-------------------------
             1 |                    10 |                      22
             1 |                    10 |                      11
             1 |                     1 |                      51
             1 |                    -4 |                      -1
             1 |                    -7 |                      -3
(5 rows)

\c :TEST_DBNAME :ROLE_SUPERUSER
DELETE FROM _timescaledb_catalog.continuous_agg where mat_hypertable_id =  2;
DELETE FROM _timescaledb_config.bgw_job WHERE id = 2;
\c :TEST_DBNAME :ROLE_DEFAULT_PERM_USER
DROP TABLE continuous_agg_test CASCADE;
\c :TEST_DBNAME :ROLE_SUPERUSER
TRUNCATE _timescaledb_catalog.continuous_aggs_hypertable_invalidation_log;
TRUNCATE _timescaledb_catalog.continuous_aggs_invalidation_threshold;
\c :TEST_DBNAME :ROLE_DEFAULT_PERM_USER
-- CREATE VIEW creates the invalidation trigger correctly
CREATE TABLE ca_inval_test(time int);
SELECT create_hypertable('ca_inval_test', 'time', chunk_time_interval=> 10);
NOTICE:  adding not-null constraint to column "time"
     create_hypertable      
----------------------------
 (3,public,ca_inval_test,t)
(1 row)

CREATE OR REPLACE FUNCTION integer_now_test2() returns int LANGUAGE SQL STABLE as $$ SELECT coalesce(max(time), 0) FROM ca_inval_test $$;
SELECT set_integer_now_func('ca_inval_test', 'integer_now_test2');
 set_integer_now_func 
----------------------
 
(1 row)

CREATE MATERIALIZED VIEW cit_view
    WITH (timescaledb.continuous, timescaledb.materialized_only=false)
    AS SELECT time_bucket('5', time), COUNT(time)
        FROM ca_inval_test
        GROUP BY 1 WITH NO DATA;
INSERT INTO ca_inval_test SELECT generate_series(0, 5);
SELECT * FROM _timescaledb_catalog.continuous_aggs_invalidation_threshold;
 hypertable_id |  watermark  
---------------+-------------
             3 | -2147483648
(1 row)

SELECT * from _timescaledb_catalog.continuous_aggs_hypertable_invalidation_log;
 hypertable_id | lowest_modified_value | greatest_modified_value 
---------------+-----------------------+-------------------------
(0 rows)

\c :TEST_DBNAME :ROLE_SUPERUSER
UPDATE _timescaledb_catalog.continuous_aggs_invalidation_threshold
SET watermark = 15
WHERE hypertable_id = 3;
\c :TEST_DBNAME :ROLE_DEFAULT_PERM_USER
INSERT INTO ca_inval_test SELECT generate_series(5, 15);
SELECT * FROM _timescaledb_catalog.continuous_aggs_invalidation_threshold;
 hypertable_id | watermark 
---------------+-----------
             3 |        15
(1 row)

SELECT * from _timescaledb_catalog.continuous_aggs_hypertable_invalidation_log;
 hypertable_id | lowest_modified_value | greatest_modified_value 
---------------+-----------------------+-------------------------
             3 |                     5 |                      15
(1 row)

INSERT INTO ca_inval_test SELECT generate_series(16, 20);
SELECT * FROM _timescaledb_catalog.continuous_aggs_invalidation_threshold;
 hypertable_id | watermark 
---------------+-----------
             3 |        15
(1 row)

SELECT * from _timescaledb_catalog.continuous_aggs_hypertable_invalidation_log;
 hypertable_id | lowest_modified_value | greatest_modified_value 
---------------+-----------------------+-------------------------
             3 |                     5 |                      15
(1 row)

\c :TEST_DBNAME :ROLE_SUPERUSER
TRUNCATE _timescaledb_catalog.continuous_aggs_hypertable_invalidation_log;
\c :TEST_DBNAME :ROLE_DEFAULT_PERM_USER
-- updates below the threshold update both the old and new values
UPDATE ca_inval_test SET time = 5 WHERE time = 6;
UPDATE ca_inval_test SET time = 7 WHERE time = 5;
UPDATE ca_inval_test SET time = 17 WHERE time = 14;
UPDATE ca_inval_test SET time = 12 WHERE time = 16;
-- updates purely above the threshold are not logged
UPDATE ca_inval_test SET time = 19 WHERE time = 18;
UPDATE ca_inval_test SET time = 17 WHERE time = 19;
SELECT * FROM _timescaledb_catalog.continuous_aggs_invalidation_threshold;
 hypertable_id | watermark 
---------------+-----------
             3 |        15
(1 row)

SELECT * from _timescaledb_catalog.continuous_aggs_hypertable_invalidation_log;
 hypertable_id | lowest_modified_value | greatest_modified_value 
---------------+-----------------------+-------------------------
             3 |                     5 |                       6
             3 |                     5 |                       7
             3 |                    14 |                      17
             3 |                    12 |                      16
(4 rows)

DROP TABLE ca_inval_test CASCADE;
NOTICE:  drop cascades to 3 other objects
\c :TEST_DBNAME :ROLE_SUPERUSER
TRUNCATE _timescaledb_catalog.continuous_aggs_hypertable_invalidation_log;
TRUNCATE _timescaledb_catalog.continuous_aggs_invalidation_threshold;
\c :TEST_DBNAME :ROLE_DEFAULT_PERM_USER
-- invalidation trigger is created correctly on chunks that existed before
-- the view was created
CREATE TABLE ts_continuous_test(time INTEGER, location INTEGER);
    SELECT create_hypertable('ts_continuous_test', 'time', chunk_time_interval => 10);
NOTICE:  adding not-null constraint to column "time"
        create_hypertable        
---------------------------------
 (5,public,ts_continuous_test,t)
(1 row)

CREATE OR REPLACE FUNCTION integer_now_test3() returns int LANGUAGE SQL STABLE as $$ SELECT coalesce(max(time), 0) FROM ts_continuous_test $$;
SELECT set_integer_now_func('ts_continuous_test', 'integer_now_test3');
 set_integer_now_func 
----------------------
 
(1 row)

INSERT INTO ts_continuous_test SELECT i, i FROM
    (SELECT generate_series(0, 29) AS i) AS i;
CREATE MATERIALIZED VIEW continuous_view
    WITH (timescaledb.continuous, timescaledb.materialized_only=false)
    AS SELECT time_bucket('5', time), COUNT(location)
        FROM ts_continuous_test
        GROUP BY 1 WITH NO DATA;
SELECT * FROM _timescaledb_catalog.continuous_aggs_invalidation_threshold;
 hypertable_id |  watermark  
---------------+-------------
             5 | -2147483648
(1 row)

SELECT * from _timescaledb_catalog.continuous_aggs_hypertable_invalidation_log;
 hypertable_id | lowest_modified_value | greatest_modified_value 
---------------+-----------------------+-------------------------
(0 rows)

\c :TEST_DBNAME :ROLE_SUPERUSER
UPDATE _timescaledb_catalog.continuous_aggs_invalidation_threshold
SET watermark = 2
WHERE hypertable_id = 5;
\c :TEST_DBNAME :ROLE_DEFAULT_PERM_USER
INSERT INTO ts_continuous_test VALUES (1, 1);
SELECT * FROM _timescaledb_catalog.continuous_aggs_invalidation_threshold;
 hypertable_id | watermark 
---------------+-----------
             5 |         2
(1 row)

SELECT * from _timescaledb_catalog.continuous_aggs_hypertable_invalidation_log;
 hypertable_id | lowest_modified_value | greatest_modified_value 
---------------+-----------------------+-------------------------
             5 |                     1 |                       1
(1 row)

-- aborts don't get written
BEGIN;
    INSERT INTO ts_continuous_test VALUES (-20, -20);
ABORT;
SELECT * FROM _timescaledb_catalog.continuous_aggs_invalidation_threshold;
 hypertable_id | watermark 
---------------+-----------
             5 |         2
(1 row)

SELECT * from _timescaledb_catalog.continuous_aggs_hypertable_invalidation_log;
 hypertable_id | lowest_modified_value | greatest_modified_value 
---------------+-----------------------+-------------------------
             5 |                     1 |                       1
(1 row)

DROP TABLE ts_continuous_test CASCADE;
NOTICE:  drop cascades to 3 other objects
----
-- Test watermark invalidation and chunk exclusion with prepared and ad-hoc queries
----
CREATE TABLE chunks(time timestamptz, device int, value float);
SELECT FROM create_hypertable('chunks','time',chunk_time_interval:='1d'::interval);
NOTICE:  adding not-null constraint to column "time"
--
(1 row)

CREATE MATERIALIZED VIEW chunks_hourly WITH (timescaledb.continuous)
    AS SELECT time_bucket('1 hour', time) AS bucket, device, avg(value) FROM chunks GROUP BY bucket, device;
NOTICE:  continuous aggregate "chunks_hourly" is already up-to-date
ALTER MATERIALIZED VIEW chunks_hourly set (timescaledb.materialized_only = false);
-- Get id fg the materialization hypertable
SELECT id AS "MAT_HT_ID" FROM _timescaledb_catalog.hypertable
    WHERE table_name=(
        SELECT materialization_hypertable_name
            FROM timescaledb_information.continuous_aggregates
            WHERE view_name='chunks_hourly'
    ) \gset
SELECT materialization_hypertable_schema || '.' || materialization_hypertable_name AS "MAT_HT_NAME"
    FROM timescaledb_information.continuous_aggregates
    WHERE view_name='chunks_hourly'
\gset
-- Prepared scan on hypertable (identical to the query of a real-time CAgg)
PREPARE ht_scan_realtime AS
   SELECT bucket, device, avg
   FROM :MAT_HT_NAME
  WHERE bucket < COALESCE(_timescaledb_functions.to_timestamp(_timescaledb_functions.cagg_watermark(:MAT_HT_ID)), '-infinity'::timestamp with time zone)
UNION ALL
 SELECT time_bucket('01:00:00'::interval, chunks."time") AS bucket,
    chunks.device,
    avg(chunks.value) AS avg
   FROM chunks
  WHERE chunks."time" >= COALESCE(_timescaledb_functions.to_timestamp(_timescaledb_functions.cagg_watermark(:MAT_HT_ID)), '-infinity'::timestamp with time zone)
  GROUP BY (time_bucket('01:00:00'::interval, chunks."time")), chunks.device;
PREPARE cagg_scan AS SELECT * FROM chunks_hourly;
:EXPLAIN_ANALYZE EXECUTE ht_scan_realtime;
                                  QUERY PLAN                                  
------------------------------------------------------------------------------
 HashAggregate (actual rows=0 loops=1)
   Group Key: time_bucket('@ 1 hour'::interval, chunks."time"), chunks.device
   Batches: 1 
   ->  Result (actual rows=0 loops=1)
         One-Time Filter: false
(5 rows)

INSERT INTO chunks VALUES ('1901-08-01 01:01:01+01', 1, 2);
CALL refresh_continuous_aggregate('chunks_hourly', '1900-01-01', '2021-06-01');
SELECT * FROM _timescaledb_functions.to_timestamp(_timescaledb_functions.cagg_watermark(:MAT_HT_ID));
         to_timestamp         
------------------------------
 Wed Jul 31 17:00:00 1901 PST
(1 row)

:EXPLAIN_ANALYZE EXECUTE ht_scan_realtime;
                                                         QUERY PLAN                                                          
-----------------------------------------------------------------------------------------------------------------------------
 Append (actual rows=1 loops=1)
   ->  Index Scan using _hyper_8_17_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_17_chunk (actual rows=1 loops=1)
         Index Cond: (bucket < 'Wed Jul 31 17:00:00 1901 PST'::timestamp with time zone)
   ->  HashAggregate (actual rows=0 loops=1)
         Group Key: time_bucket('@ 1 hour'::interval, _hyper_7_16_chunk."time"), _hyper_7_16_chunk.device
         Batches: 1 
         ->  Result (actual rows=0 loops=1)
               ->  Index Scan using _hyper_7_16_chunk_chunks_time_idx on _hyper_7_16_chunk (actual rows=0 loops=1)
                     Index Cond: ("time" >= 'Wed Jul 31 17:00:00 1901 PST'::timestamp with time zone)
(9 rows)

-- Compare prepared statement with ad-hoc query
EXECUTE cagg_scan;
            bucket            | device | avg 
------------------------------+--------+-----
 Wed Jul 31 16:00:00 1901 PST |      1 |   2
(1 row)

SELECT * FROM chunks_hourly;
            bucket            | device | avg 
------------------------------+--------+-----
 Wed Jul 31 16:00:00 1901 PST |      1 |   2
(1 row)

-- Add new chunks to the unmaterialized part of the CAgg
INSERT INTO chunks VALUES ('1910-08-01 01:01:01+01', 1, 2);
:EXPLAIN_ANALYZE EXECUTE cagg_scan;
                                                         QUERY PLAN                                                          
-----------------------------------------------------------------------------------------------------------------------------
 Append (actual rows=2 loops=1)
   ->  Index Scan using _hyper_8_17_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_17_chunk (actual rows=1 loops=1)
         Index Cond: (bucket < 'Wed Jul 31 17:00:00 1901 PST'::timestamp with time zone)
   ->  HashAggregate (actual rows=1 loops=1)
         Group Key: time_bucket('@ 1 hour'::interval, _hyper_7_16_chunk."time"), _hyper_7_16_chunk.device
         Batches: 1 
         ->  Result (actual rows=1 loops=1)
               ->  Append (actual rows=1 loops=1)
                     ->  Index Scan using _hyper_7_16_chunk_chunks_time_idx on _hyper_7_16_chunk (actual rows=0 loops=1)
                           Index Cond: ("time" >= 'Wed Jul 31 17:00:00 1901 PST'::timestamp with time zone)
                     ->  Index Scan using _hyper_7_18_chunk_chunks_time_idx on _hyper_7_18_chunk (actual rows=1 loops=1)
                           Index Cond: ("time" >= 'Wed Jul 31 17:00:00 1901 PST'::timestamp with time zone)
(12 rows)

:EXPLAIN_ANALYZE SELECT * FROM chunks_hourly;
                                                         QUERY PLAN                                                          
-----------------------------------------------------------------------------------------------------------------------------
 Append (actual rows=2 loops=1)
   ->  Index Scan using _hyper_8_17_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_17_chunk (actual rows=1 loops=1)
         Index Cond: (bucket < 'Wed Jul 31 17:00:00 1901 PST'::timestamp with time zone)
   ->  HashAggregate (actual rows=1 loops=1)
         Group Key: time_bucket('@ 1 hour'::interval, _hyper_7_16_chunk."time"), _hyper_7_16_chunk.device
         Batches: 1 
         ->  Result (actual rows=1 loops=1)
               ->  Append (actual rows=1 loops=1)
                     ->  Index Scan using _hyper_7_16_chunk_chunks_time_idx on _hyper_7_16_chunk (actual rows=0 loops=1)
                           Index Cond: ("time" >= 'Wed Jul 31 17:00:00 1901 PST'::timestamp with time zone)
                     ->  Index Scan using _hyper_7_18_chunk_chunks_time_idx on _hyper_7_18_chunk (actual rows=1 loops=1)
                           Index Cond: ("time" >= 'Wed Jul 31 17:00:00 1901 PST'::timestamp with time zone)
(12 rows)

INSERT INTO chunks VALUES ('1911-08-01 01:01:01+01', 1, 2);
:EXPLAIN_ANALYZE EXECUTE cagg_scan;
                                                         QUERY PLAN                                                          
-----------------------------------------------------------------------------------------------------------------------------
 Append (actual rows=3 loops=1)
   ->  Index Scan using _hyper_8_17_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_17_chunk (actual rows=1 loops=1)
         Index Cond: (bucket < 'Wed Jul 31 17:00:00 1901 PST'::timestamp with time zone)
   ->  HashAggregate (actual rows=2 loops=1)
         Group Key: time_bucket('@ 1 hour'::interval, _hyper_7_16_chunk."time"), _hyper_7_16_chunk.device
         Batches: 1 
         ->  Result (actual rows=2 loops=1)
               ->  Append (actual rows=2 loops=1)
                     ->  Index Scan using _hyper_7_16_chunk_chunks_time_idx on _hyper_7_16_chunk (actual rows=0 loops=1)
                           Index Cond: ("time" >= 'Wed Jul 31 17:00:00 1901 PST'::timestamp with time zone)
                     ->  Index Scan using _hyper_7_18_chunk_chunks_time_idx on _hyper_7_18_chunk (actual rows=1 loops=1)
                           Index Cond: ("time" >= 'Wed Jul 31 17:00:00 1901 PST'::timestamp with time zone)
                     ->  Index Scan using _hyper_7_19_chunk_chunks_time_idx on _hyper_7_19_chunk (actual rows=1 loops=1)
                           Index Cond: ("time" >= 'Wed Jul 31 17:00:00 1901 PST'::timestamp with time zone)
(14 rows)

:EXPLAIN_ANALYZE SELECT * FROM chunks_hourly;
                                                         QUERY PLAN                                                          
-----------------------------------------------------------------------------------------------------------------------------
 Append (actual rows=3 loops=1)
   ->  Index Scan using _hyper_8_17_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_17_chunk (actual rows=1 loops=1)
         Index Cond: (bucket < 'Wed Jul 31 17:00:00 1901 PST'::timestamp with time zone)
   ->  HashAggregate (actual rows=2 loops=1)
         Group Key: time_bucket('@ 1 hour'::interval, _hyper_7_16_chunk."time"), _hyper_7_16_chunk.device
         Batches: 1 
         ->  Result (actual rows=2 loops=1)
               ->  Append (actual rows=2 loops=1)
                     ->  Index Scan using _hyper_7_16_chunk_chunks_time_idx on _hyper_7_16_chunk (actual rows=0 loops=1)
                           Index Cond: ("time" >= 'Wed Jul 31 17:00:00 1901 PST'::timestamp with time zone)
                     ->  Index Scan using _hyper_7_18_chunk_chunks_time_idx on _hyper_7_18_chunk (actual rows=1 loops=1)
                           Index Cond: ("time" >= 'Wed Jul 31 17:00:00 1901 PST'::timestamp with time zone)
                     ->  Index Scan using _hyper_7_19_chunk_chunks_time_idx on _hyper_7_19_chunk (actual rows=1 loops=1)
                           Index Cond: ("time" >= 'Wed Jul 31 17:00:00 1901 PST'::timestamp with time zone)
(14 rows)

-- Materialize CAgg and check for plan time chunk exclusion
CALL refresh_continuous_aggregate('chunks_hourly', '1900-01-01', '2021-06-01');
:EXPLAIN_ANALYZE EXECUTE cagg_scan;
                                                            QUERY PLAN                                                             
-----------------------------------------------------------------------------------------------------------------------------------
 Append (actual rows=3 loops=1)
   ->  Append (actual rows=3 loops=1)
         ->  Index Scan using _hyper_8_17_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_17_chunk (actual rows=1 loops=1)
               Index Cond: (bucket < 'Mon Jul 31 17:00:00 1911 PST'::timestamp with time zone)
         ->  Index Scan using _hyper_8_20_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_20_chunk (actual rows=1 loops=1)
               Index Cond: (bucket < 'Mon Jul 31 17:00:00 1911 PST'::timestamp with time zone)
         ->  Index Scan using _hyper_8_21_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_21_chunk (actual rows=1 loops=1)
               Index Cond: (bucket < 'Mon Jul 31 17:00:00 1911 PST'::timestamp with time zone)
   ->  HashAggregate (actual rows=0 loops=1)
         Group Key: time_bucket('@ 1 hour'::interval, _hyper_7_19_chunk."time"), _hyper_7_19_chunk.device
         Batches: 1 
         ->  Result (actual rows=0 loops=1)
               ->  Index Scan using _hyper_7_19_chunk_chunks_time_idx on _hyper_7_19_chunk (actual rows=0 loops=1)
                     Index Cond: ("time" >= 'Mon Jul 31 17:00:00 1911 PST'::timestamp with time zone)
(14 rows)

:EXPLAIN_ANALYZE SELECT * FROM chunks_hourly;
                                                            QUERY PLAN                                                             
-----------------------------------------------------------------------------------------------------------------------------------
 Append (actual rows=3 loops=1)
   ->  Append (actual rows=3 loops=1)
         ->  Index Scan using _hyper_8_17_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_17_chunk (actual rows=1 loops=1)
               Index Cond: (bucket < 'Mon Jul 31 17:00:00 1911 PST'::timestamp with time zone)
         ->  Index Scan using _hyper_8_20_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_20_chunk (actual rows=1 loops=1)
               Index Cond: (bucket < 'Mon Jul 31 17:00:00 1911 PST'::timestamp with time zone)
         ->  Index Scan using _hyper_8_21_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_21_chunk (actual rows=1 loops=1)
               Index Cond: (bucket < 'Mon Jul 31 17:00:00 1911 PST'::timestamp with time zone)
   ->  HashAggregate (actual rows=0 loops=1)
         Group Key: time_bucket('@ 1 hour'::interval, _hyper_7_19_chunk."time"), _hyper_7_19_chunk.device
         Batches: 1 
         ->  Result (actual rows=0 loops=1)
               ->  Index Scan using _hyper_7_19_chunk_chunks_time_idx on _hyper_7_19_chunk (actual rows=0 loops=1)
                     Index Cond: ("time" >= 'Mon Jul 31 17:00:00 1911 PST'::timestamp with time zone)
(14 rows)

-- Check plan when chunk_append and constraint_aware_append cannot be used
-- There should be no plans for scans of chunks that are materialized in the CAgg
-- on the underlying hypertable
SET timescaledb.enable_chunk_append = OFF;
SET timescaledb.enable_constraint_aware_append = OFF;
:EXPLAIN_ANALYZE SELECT * FROM chunks_hourly;
                                                            QUERY PLAN                                                             
-----------------------------------------------------------------------------------------------------------------------------------
 Append (actual rows=3 loops=1)
   ->  Append (actual rows=3 loops=1)
         ->  Index Scan using _hyper_8_17_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_17_chunk (actual rows=1 loops=1)
               Index Cond: (bucket < 'Mon Jul 31 17:00:00 1911 PST'::timestamp with time zone)
         ->  Index Scan using _hyper_8_20_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_20_chunk (actual rows=1 loops=1)
               Index Cond: (bucket < 'Mon Jul 31 17:00:00 1911 PST'::timestamp with time zone)
         ->  Index Scan using _hyper_8_21_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_21_chunk (actual rows=1 loops=1)
               Index Cond: (bucket < 'Mon Jul 31 17:00:00 1911 PST'::timestamp with time zone)
   ->  HashAggregate (actual rows=0 loops=1)
         Group Key: time_bucket('@ 1 hour'::interval, _hyper_7_19_chunk."time"), _hyper_7_19_chunk.device
         Batches: 1 
         ->  Result (actual rows=0 loops=1)
               ->  Index Scan using _hyper_7_19_chunk_chunks_time_idx on _hyper_7_19_chunk (actual rows=0 loops=1)
                     Index Cond: ("time" >= 'Mon Jul 31 17:00:00 1911 PST'::timestamp with time zone)
(14 rows)

RESET timescaledb.enable_chunk_append;
RESET timescaledb.enable_constraint_aware_append;
-- Insert new values and check watermark changes
INSERT INTO chunks VALUES ('1920-08-01 01:01:01+01', 1, 2);
CALL refresh_continuous_aggregate('chunks_hourly', '1900-01-01', '2021-06-01');
SELECT * FROM _timescaledb_functions.to_timestamp(_timescaledb_functions.cagg_watermark(:MAT_HT_ID));
         to_timestamp         
------------------------------
 Sat Jul 31 17:00:00 1920 PST
(1 row)

:EXPLAIN_ANALYZE EXECUTE ht_scan_realtime;
                                                            QUERY PLAN                                                             
-----------------------------------------------------------------------------------------------------------------------------------
 Append (actual rows=4 loops=1)
   ->  Append (actual rows=4 loops=1)
         ->  Index Scan using _hyper_8_17_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_17_chunk (actual rows=1 loops=1)
               Index Cond: (bucket < 'Sat Jul 31 17:00:00 1920 PST'::timestamp with time zone)
         ->  Index Scan using _hyper_8_20_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_20_chunk (actual rows=1 loops=1)
               Index Cond: (bucket < 'Sat Jul 31 17:00:00 1920 PST'::timestamp with time zone)
         ->  Index Scan using _hyper_8_21_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_21_chunk (actual rows=1 loops=1)
               Index Cond: (bucket < 'Sat Jul 31 17:00:00 1920 PST'::timestamp with time zone)
         ->  Index Scan using _hyper_8_23_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_23_chunk (actual rows=1 loops=1)
               Index Cond: (bucket < 'Sat Jul 31 17:00:00 1920 PST'::timestamp with time zone)
   ->  HashAggregate (actual rows=0 loops=1)
         Group Key: time_bucket('@ 1 hour'::interval, _hyper_7_22_chunk."time"), _hyper_7_22_chunk.device
         Batches: 1 
         ->  Result (actual rows=0 loops=1)
               ->  Index Scan using _hyper_7_22_chunk_chunks_time_idx on _hyper_7_22_chunk (actual rows=0 loops=1)
                     Index Cond: ("time" >= 'Sat Jul 31 17:00:00 1920 PST'::timestamp with time zone)
(16 rows)

-- Compare prepared statement with ad-hoc query
EXECUTE cagg_scan;
            bucket            | device | avg 
------------------------------+--------+-----
 Wed Jul 31 16:00:00 1901 PST |      1 |   2
 Sun Jul 31 16:00:00 1910 PST |      1 |   2
 Mon Jul 31 16:00:00 1911 PST |      1 |   2
 Sat Jul 31 16:00:00 1920 PST |      1 |   2
(4 rows)

SELECT * FROM chunks_hourly;
            bucket            | device | avg 
------------------------------+--------+-----
 Wed Jul 31 16:00:00 1901 PST |      1 |   2
 Sun Jul 31 16:00:00 1910 PST |      1 |   2
 Mon Jul 31 16:00:00 1911 PST |      1 |   2
 Sat Jul 31 16:00:00 1920 PST |      1 |   2
(4 rows)

INSERT INTO chunks VALUES ('1930-08-01 01:01:01+01', 1, 2);
CALL refresh_continuous_aggregate('chunks_hourly', '1900-01-01', '2021-06-01');
SELECT * FROM _timescaledb_functions.to_timestamp(_timescaledb_functions.cagg_watermark(:MAT_HT_ID));
         to_timestamp         
------------------------------
 Thu Jul 31 17:00:00 1930 PST
(1 row)

:EXPLAIN_ANALYZE EXECUTE ht_scan_realtime;
                                                            QUERY PLAN                                                             
-----------------------------------------------------------------------------------------------------------------------------------
 Append (actual rows=5 loops=1)
   ->  Append (actual rows=5 loops=1)
         ->  Index Scan using _hyper_8_17_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_17_chunk (actual rows=1 loops=1)
               Index Cond: (bucket < 'Thu Jul 31 17:00:00 1930 PST'::timestamp with time zone)
         ->  Index Scan using _hyper_8_20_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_20_chunk (actual rows=1 loops=1)
               Index Cond: (bucket < 'Thu Jul 31 17:00:00 1930 PST'::timestamp with time zone)
         ->  Index Scan using _hyper_8_21_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_21_chunk (actual rows=1 loops=1)
               Index Cond: (bucket < 'Thu Jul 31 17:00:00 1930 PST'::timestamp with time zone)
         ->  Index Scan using _hyper_8_23_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_23_chunk (actual rows=1 loops=1)
               Index Cond: (bucket < 'Thu Jul 31 17:00:00 1930 PST'::timestamp with time zone)
         ->  Index Scan using _hyper_8_25_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_25_chunk (actual rows=1 loops=1)
               Index Cond: (bucket < 'Thu Jul 31 17:00:00 1930 PST'::timestamp with time zone)
   ->  HashAggregate (actual rows=0 loops=1)
         Group Key: time_bucket('@ 1 hour'::interval, _hyper_7_24_chunk."time"), _hyper_7_24_chunk.device
         Batches: 1 
         ->  Result (actual rows=0 loops=1)
               ->  Index Scan using _hyper_7_24_chunk_chunks_time_idx on _hyper_7_24_chunk (actual rows=0 loops=1)
                     Index Cond: ("time" >= 'Thu Jul 31 17:00:00 1930 PST'::timestamp with time zone)
(18 rows)

-- Two invalidations without prepared statement execution between
INSERT INTO chunks VALUES ('1931-08-01 01:01:01+01', 1, 2);
CALL refresh_continuous_aggregate('chunks_hourly', '1900-01-01', '2021-06-01');
INSERT INTO chunks VALUES ('1932-08-01 01:01:01+01', 1, 2);
CALL refresh_continuous_aggregate('chunks_hourly', '1900-01-01', '2021-06-01');
SELECT * FROM _timescaledb_functions.to_timestamp(_timescaledb_functions.cagg_watermark(:MAT_HT_ID));
         to_timestamp         
------------------------------
 Sun Jul 31 17:00:00 1932 PST
(1 row)

:EXPLAIN_ANALYZE EXECUTE ht_scan_realtime;
                                                            QUERY PLAN                                                             
-----------------------------------------------------------------------------------------------------------------------------------
 Append (actual rows=7 loops=1)
   ->  Append (actual rows=7 loops=1)
         ->  Index Scan using _hyper_8_17_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_17_chunk (actual rows=1 loops=1)
               Index Cond: (bucket < 'Sun Jul 31 17:00:00 1932 PST'::timestamp with time zone)
         ->  Index Scan using _hyper_8_20_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_20_chunk (actual rows=1 loops=1)
               Index Cond: (bucket < 'Sun Jul 31 17:00:00 1932 PST'::timestamp with time zone)
         ->  Index Scan using _hyper_8_21_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_21_chunk (actual rows=1 loops=1)
               Index Cond: (bucket < 'Sun Jul 31 17:00:00 1932 PST'::timestamp with time zone)
         ->  Index Scan using _hyper_8_23_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_23_chunk (actual rows=1 loops=1)
               Index Cond: (bucket < 'Sun Jul 31 17:00:00 1932 PST'::timestamp with time zone)
         ->  Index Scan using _hyper_8_25_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_25_chunk (actual rows=1 loops=1)
               Index Cond: (bucket < 'Sun Jul 31 17:00:00 1932 PST'::timestamp with time zone)
         ->  Index Scan using _hyper_8_27_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_27_chunk (actual rows=1 loops=1)
               Index Cond: (bucket < 'Sun Jul 31 17:00:00 1932 PST'::timestamp with time zone)
         ->  Index Scan using _hyper_8_29_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_29_chunk (actual rows=1 loops=1)
               Index Cond: (bucket < 'Sun Jul 31 17:00:00 1932 PST'::timestamp with time zone)
   ->  HashAggregate (actual rows=0 loops=1)
         Group Key: time_bucket('@ 1 hour'::interval, _hyper_7_28_chunk."time"), _hyper_7_28_chunk.device
         Batches: 1 
         ->  Result (actual rows=0 loops=1)
               ->  Index Scan using _hyper_7_28_chunk_chunks_time_idx on _hyper_7_28_chunk (actual rows=0 loops=1)
                     Index Cond: ("time" >= 'Sun Jul 31 17:00:00 1932 PST'::timestamp with time zone)
(22 rows)

-- Multiple prepared statement executions followed by one invalidation
:EXPLAIN_ANALYZE EXECUTE ht_scan_realtime;
                                                            QUERY PLAN                                                             
-----------------------------------------------------------------------------------------------------------------------------------
 Append (actual rows=7 loops=1)
   ->  Append (actual rows=7 loops=1)
         ->  Index Scan using _hyper_8_17_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_17_chunk (actual rows=1 loops=1)
               Index Cond: (bucket < 'Sun Jul 31 17:00:00 1932 PST'::timestamp with time zone)
         ->  Index Scan using _hyper_8_20_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_20_chunk (actual rows=1 loops=1)
               Index Cond: (bucket < 'Sun Jul 31 17:00:00 1932 PST'::timestamp with time zone)
         ->  Index Scan using _hyper_8_21_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_21_chunk (actual rows=1 loops=1)
               Index Cond: (bucket < 'Sun Jul 31 17:00:00 1932 PST'::timestamp with time zone)
         ->  Index Scan using _hyper_8_23_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_23_chunk (actual rows=1 loops=1)
               Index Cond: (bucket < 'Sun Jul 31 17:00:00 1932 PST'::timestamp with time zone)
         ->  Index Scan using _hyper_8_25_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_25_chunk (actual rows=1 loops=1)
               Index Cond: (bucket < 'Sun Jul 31 17:00:00 1932 PST'::timestamp with time zone)
         ->  Index Scan using _hyper_8_27_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_27_chunk (actual rows=1 loops=1)
               Index Cond: (bucket < 'Sun Jul 31 17:00:00 1932 PST'::timestamp with time zone)
         ->  Index Scan using _hyper_8_29_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_29_chunk (actual rows=1 loops=1)
               Index Cond: (bucket < 'Sun Jul 31 17:00:00 1932 PST'::timestamp with time zone)
   ->  HashAggregate (actual rows=0 loops=1)
         Group Key: time_bucket('@ 1 hour'::interval, _hyper_7_28_chunk."time"), _hyper_7_28_chunk.device
         Batches: 1 
         ->  Result (actual rows=0 loops=1)
               ->  Index Scan using _hyper_7_28_chunk_chunks_time_idx on _hyper_7_28_chunk (actual rows=0 loops=1)
                     Index Cond: ("time" >= 'Sun Jul 31 17:00:00 1932 PST'::timestamp with time zone)
(22 rows)

:EXPLAIN_ANALYZE EXECUTE ht_scan_realtime;
                                                            QUERY PLAN                                                             
-----------------------------------------------------------------------------------------------------------------------------------
 Append (actual rows=7 loops=1)
   ->  Append (actual rows=7 loops=1)
         ->  Index Scan using _hyper_8_17_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_17_chunk (actual rows=1 loops=1)
               Index Cond: (bucket < 'Sun Jul 31 17:00:00 1932 PST'::timestamp with time zone)
         ->  Index Scan using _hyper_8_20_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_20_chunk (actual rows=1 loops=1)
               Index Cond: (bucket < 'Sun Jul 31 17:00:00 1932 PST'::timestamp with time zone)
         ->  Index Scan using _hyper_8_21_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_21_chunk (actual rows=1 loops=1)
               Index Cond: (bucket < 'Sun Jul 31 17:00:00 1932 PST'::timestamp with time zone)
         ->  Index Scan using _hyper_8_23_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_23_chunk (actual rows=1 loops=1)
               Index Cond: (bucket < 'Sun Jul 31 17:00:00 1932 PST'::timestamp with time zone)
         ->  Index Scan using _hyper_8_25_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_25_chunk (actual rows=1 loops=1)
               Index Cond: (bucket < 'Sun Jul 31 17:00:00 1932 PST'::timestamp with time zone)
         ->  Index Scan using _hyper_8_27_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_27_chunk (actual rows=1 loops=1)
               Index Cond: (bucket < 'Sun Jul 31 17:00:00 1932 PST'::timestamp with time zone)
         ->  Index Scan using _hyper_8_29_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_29_chunk (actual rows=1 loops=1)
               Index Cond: (bucket < 'Sun Jul 31 17:00:00 1932 PST'::timestamp with time zone)
   ->  HashAggregate (actual rows=0 loops=1)
         Group Key: time_bucket('@ 1 hour'::interval, _hyper_7_28_chunk."time"), _hyper_7_28_chunk.device
         Batches: 1 
         ->  Result (actual rows=0 loops=1)
               ->  Index Scan using _hyper_7_28_chunk_chunks_time_idx on _hyper_7_28_chunk (actual rows=0 loops=1)
                     Index Cond: ("time" >= 'Sun Jul 31 17:00:00 1932 PST'::timestamp with time zone)
(22 rows)

INSERT INTO chunks VALUES ('1940-08-01 01:01:01+01', 1, 2);
CALL refresh_continuous_aggregate('chunks_hourly', '1900-01-01', '2021-06-01');
:EXPLAIN_ANALYZE EXECUTE ht_scan_realtime;
                                                            QUERY PLAN                                                             
-----------------------------------------------------------------------------------------------------------------------------------
 Append (actual rows=8 loops=1)
   ->  Append (actual rows=8 loops=1)
         ->  Index Scan using _hyper_8_17_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_17_chunk (actual rows=1 loops=1)
               Index Cond: (bucket < 'Wed Jul 31 17:00:00 1940 PST'::timestamp with time zone)
         ->  Index Scan using _hyper_8_20_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_20_chunk (actual rows=1 loops=1)
               Index Cond: (bucket < 'Wed Jul 31 17:00:00 1940 PST'::timestamp with time zone)
         ->  Index Scan using _hyper_8_21_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_21_chunk (actual rows=1 loops=1)
               Index Cond: (bucket < 'Wed Jul 31 17:00:00 1940 PST'::timestamp with time zone)
         ->  Index Scan using _hyper_8_23_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_23_chunk (actual rows=1 loops=1)
               Index Cond: (bucket < 'Wed Jul 31 17:00:00 1940 PST'::timestamp with time zone)
         ->  Index Scan using _hyper_8_25_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_25_chunk (actual rows=1 loops=1)
               Index Cond: (bucket < 'Wed Jul 31 17:00:00 1940 PST'::timestamp with time zone)
         ->  Index Scan using _hyper_8_27_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_27_chunk (actual rows=1 loops=1)
               Index Cond: (bucket < 'Wed Jul 31 17:00:00 1940 PST'::timestamp with time zone)
         ->  Index Scan using _hyper_8_29_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_29_chunk (actual rows=1 loops=1)
               Index Cond: (bucket < 'Wed Jul 31 17:00:00 1940 PST'::timestamp with time zone)
         ->  Index Scan using _hyper_8_31_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_31_chunk (actual rows=1 loops=1)
               Index Cond: (bucket < 'Wed Jul 31 17:00:00 1940 PST'::timestamp with time zone)
   ->  HashAggregate (actual rows=0 loops=1)
         Group Key: time_bucket('@ 1 hour'::interval, _hyper_7_30_chunk."time"), _hyper_7_30_chunk.device
         Batches: 1 
         ->  Result (actual rows=0 loops=1)
               ->  Index Scan using _hyper_7_30_chunk_chunks_time_idx on _hyper_7_30_chunk (actual rows=0 loops=1)
                     Index Cond: ("time" >= 'Wed Jul 31 17:00:00 1940 PST'::timestamp with time zone)
(24 rows)

-- Compare prepared statement with ad-hoc query
EXECUTE cagg_scan;
            bucket            | device | avg 
------------------------------+--------+-----
 Wed Jul 31 16:00:00 1901 PST |      1 |   2
 Sun Jul 31 16:00:00 1910 PST |      1 |   2
 Mon Jul 31 16:00:00 1911 PST |      1 |   2
 Sat Jul 31 16:00:00 1920 PST |      1 |   2
 Thu Jul 31 16:00:00 1930 PST |      1 |   2
 Fri Jul 31 16:00:00 1931 PST |      1 |   2
 Sun Jul 31 16:00:00 1932 PST |      1 |   2
 Wed Jul 31 16:00:00 1940 PST |      1 |   2
(8 rows)

SELECT * FROM chunks_hourly;
            bucket            | device | avg 
------------------------------+--------+-----
 Wed Jul 31 16:00:00 1901 PST |      1 |   2
 Sun Jul 31 16:00:00 1910 PST |      1 |   2
 Mon Jul 31 16:00:00 1911 PST |      1 |   2
 Sat Jul 31 16:00:00 1920 PST |      1 |   2
 Thu Jul 31 16:00:00 1930 PST |      1 |   2
 Fri Jul 31 16:00:00 1931 PST |      1 |   2
 Sun Jul 31 16:00:00 1932 PST |      1 |   2
 Wed Jul 31 16:00:00 1940 PST |      1 |   2
(8 rows)

-- Delete data from hypertable - data is only present in cagg after this point. If the watermark in the prepared
-- statement is not moved to the most-recent watermark, we would see an empty result.
TRUNCATE chunks;
EXECUTE cagg_scan;
            bucket            | device | avg 
------------------------------+--------+-----
 Wed Jul 31 16:00:00 1901 PST |      1 |   2
 Sun Jul 31 16:00:00 1910 PST |      1 |   2
 Mon Jul 31 16:00:00 1911 PST |      1 |   2
 Sat Jul 31 16:00:00 1920 PST |      1 |   2
 Thu Jul 31 16:00:00 1930 PST |      1 |   2
 Fri Jul 31 16:00:00 1931 PST |      1 |   2
 Sun Jul 31 16:00:00 1932 PST |      1 |   2
 Wed Jul 31 16:00:00 1940 PST |      1 |   2
(8 rows)

SELECT * FROM chunks_hourly;
            bucket            | device | avg 
------------------------------+--------+-----
 Wed Jul 31 16:00:00 1901 PST |      1 |   2
 Sun Jul 31 16:00:00 1910 PST |      1 |   2
 Mon Jul 31 16:00:00 1911 PST |      1 |   2
 Sat Jul 31 16:00:00 1920 PST |      1 |   2
 Thu Jul 31 16:00:00 1930 PST |      1 |   2
 Fri Jul 31 16:00:00 1931 PST |      1 |   2
 Sun Jul 31 16:00:00 1932 PST |      1 |   2
 Wed Jul 31 16:00:00 1940 PST |      1 |   2
(8 rows)

-- Refresh the CAgg
CALL refresh_continuous_aggregate('chunks_hourly', NULL, NULL);
EXECUTE cagg_scan;
 bucket | device | avg 
--------+--------+-----
(0 rows)

SELECT * FROM chunks_hourly;
 bucket | device | avg 
--------+--------+-----
(0 rows)

-- Check new watermark
SELECT * FROM _timescaledb_functions.to_timestamp(_timescaledb_functions.cagg_watermark(:MAT_HT_ID));
         to_timestamp         
------------------------------
 Wed Jul 31 17:00:00 1940 PST
(1 row)

:EXPLAIN_ANALYZE EXECUTE ht_scan_realtime;
                                                            QUERY PLAN                                                             
-----------------------------------------------------------------------------------------------------------------------------------
 Append (actual rows=0 loops=1)
   ->  Append (actual rows=0 loops=1)
         ->  Index Scan using _hyper_8_17_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_17_chunk (actual rows=0 loops=1)
               Index Cond: (bucket < 'Wed Jul 31 17:00:00 1940 PST'::timestamp with time zone)
         ->  Index Scan using _hyper_8_20_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_20_chunk (actual rows=0 loops=1)
               Index Cond: (bucket < 'Wed Jul 31 17:00:00 1940 PST'::timestamp with time zone)
         ->  Index Scan using _hyper_8_21_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_21_chunk (actual rows=0 loops=1)
               Index Cond: (bucket < 'Wed Jul 31 17:00:00 1940 PST'::timestamp with time zone)
         ->  Index Scan using _hyper_8_23_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_23_chunk (actual rows=0 loops=1)
               Index Cond: (bucket < 'Wed Jul 31 17:00:00 1940 PST'::timestamp with time zone)
         ->  Index Scan using _hyper_8_25_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_25_chunk (actual rows=0 loops=1)
               Index Cond: (bucket < 'Wed Jul 31 17:00:00 1940 PST'::timestamp with time zone)
         ->  Index Scan using _hyper_8_27_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_27_chunk (actual rows=0 loops=1)
               Index Cond: (bucket < 'Wed Jul 31 17:00:00 1940 PST'::timestamp with time zone)
         ->  Index Scan using _hyper_8_29_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_29_chunk (actual rows=0 loops=1)
               Index Cond: (bucket < 'Wed Jul 31 17:00:00 1940 PST'::timestamp with time zone)
         ->  Index Scan using _hyper_8_31_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_31_chunk (actual rows=0 loops=1)
               Index Cond: (bucket < 'Wed Jul 31 17:00:00 1940 PST'::timestamp with time zone)
   ->  HashAggregate (actual rows=0 loops=1)
         Group Key: time_bucket('@ 1 hour'::interval, "time"), device
         Batches: 1 
         ->  Result (actual rows=0 loops=1)
               One-Time Filter: false
(23 rows)

-- Update after truncate
INSERT INTO chunks VALUES ('1950-08-01 01:01:01+01', 1, 2);
CALL refresh_continuous_aggregate('chunks_hourly', '1900-01-01', '2021-06-01');
SELECT * FROM _timescaledb_functions.to_timestamp(_timescaledb_functions.cagg_watermark(:MAT_HT_ID));
         to_timestamp         
------------------------------
 Mon Jul 31 17:00:00 1950 PST
(1 row)

:EXPLAIN_ANALYZE EXECUTE ht_scan_realtime;
                                                            QUERY PLAN                                                             
-----------------------------------------------------------------------------------------------------------------------------------
 Append (actual rows=1 loops=1)
   ->  Append (actual rows=1 loops=1)
         ->  Index Scan using _hyper_8_17_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_17_chunk (actual rows=0 loops=1)
               Index Cond: (bucket < 'Mon Jul 31 17:00:00 1950 PST'::timestamp with time zone)
         ->  Index Scan using _hyper_8_20_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_20_chunk (actual rows=0 loops=1)
               Index Cond: (bucket < 'Mon Jul 31 17:00:00 1950 PST'::timestamp with time zone)
         ->  Index Scan using _hyper_8_21_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_21_chunk (actual rows=0 loops=1)
               Index Cond: (bucket < 'Mon Jul 31 17:00:00 1950 PST'::timestamp with time zone)
         ->  Index Scan using _hyper_8_23_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_23_chunk (actual rows=0 loops=1)
               Index Cond: (bucket < 'Mon Jul 31 17:00:00 1950 PST'::timestamp with time zone)
         ->  Index Scan using _hyper_8_25_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_25_chunk (actual rows=0 loops=1)
               Index Cond: (bucket < 'Mon Jul 31 17:00:00 1950 PST'::timestamp with time zone)
         ->  Index Scan using _hyper_8_27_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_27_chunk (actual rows=0 loops=1)
               Index Cond: (bucket < 'Mon Jul 31 17:00:00 1950 PST'::timestamp with time zone)
         ->  Index Scan using _hyper_8_29_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_29_chunk (actual rows=0 loops=1)
               Index Cond: (bucket < 'Mon Jul 31 17:00:00 1950 PST'::timestamp with time zone)
         ->  Index Scan using _hyper_8_31_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_31_chunk (actual rows=0 loops=1)
               Index Cond: (bucket < 'Mon Jul 31 17:00:00 1950 PST'::timestamp with time zone)
         ->  Index Scan using _hyper_8_33_chunk__materialized_hypertable_8_bucket_idx on _hyper_8_33_chunk (actual rows=1 loops=1)
               Index Cond: (bucket < 'Mon Jul 31 17:00:00 1950 PST'::timestamp with time zone)
   ->  HashAggregate (actual rows=0 loops=1)
         Group Key: time_bucket('@ 1 hour'::interval, _hyper_7_32_chunk."time"), _hyper_7_32_chunk.device
         Batches: 1 
         ->  Result (actual rows=0 loops=1)
               ->  Index Scan using _hyper_7_32_chunk_chunks_time_idx on _hyper_7_32_chunk (actual rows=0 loops=1)
                     Index Cond: ("time" >= 'Mon Jul 31 17:00:00 1950 PST'::timestamp with time zone)
(26 rows)

\c :TEST_DBNAME :ROLE_SUPERUSER
TRUNCATE _timescaledb_catalog.continuous_aggs_hypertable_invalidation_log;
TRUNCATE _timescaledb_catalog.continuous_aggs_invalidation_threshold;
\c :TEST_DBNAME :ROLE_DEFAULT_PERM_USER
